---
title: "Predicting the trend of New York Data Set"
output: html_notebook
---

Using supervised learning, I am trying to set a certain range of years 2000-2020 as a test set to predict the year 2021 using the New York data. 


```{r}
library(tidyverse)
library(factoextra)
library(mosaic)
library(modelr)

```

```{r}

NYdata <- read_csv("seven-major-felony-offenses-2000-2021.csv")

years <- c('offense','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009', '2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021')

names(NYdata)<-years
NYdata_cleaned<-NYdata %>% slice(-c(1,2,3,4,13,14,15,16,17,18,19,20))

```


```{r}
#View(NYdata_cleaned2)

NYdata_cleaned_allcrimes<- NYdata_cleaned2[155:176,]
NYdata_cleaned_allcrimes<- transform(NYdata_cleaned_allcrimes, Year = as.numeric(Year))
View(NYdata_cleaned_allcrimes)
```

```{r}
NYdata_cleaned_allcrimes %>% ggplot() + geom_point(aes(Year, crime_count)) + ggtitle(labs(title = "Number of Seven Major Felony Offenses from 2000 to 2021 in NY")) #plot for trend for all the crimes from 2000 to 2020
```
```{r}
NYdata_cleaned_alloffense<- NYdata_cleaned2[1:154,] 
NYdata_cleaned_alloffense %>% ggplot() + geom_point(aes(Year, crime_count)) + ggtitle(labs(title = "Number of Seven Major Felony Offenses from 2000 to 2021 in NY")) + facet_wrap(~offense, ncol = 4) + theme(axis.text.x= element_text(angle = 60))
```

```{r}
mod <- lm(crime_count ~ Year, data = NYdata_cleaned_allcrimes )
summary(mod)
```
```{r}

modpred <- NYdata_cleaned_allcrimes %>% add_predictions(mod)
modpred
```
```{r}
modpred %>% 
  ggplot() + 
  geom_point(aes(Year,crime_count)) +
  geom_point(aes(Year,pred), col = 'red', size = 3) +
  geom_line(aes(Year,pred), col = 'red') +
  geom_segment(aes(x= Year, y= crime_count, xend = Year, yend =pred), alpha = .2) +
  ggtitle(labs(title = "Regression Line of the Total Crime in NY"))
```
The evaluation of these hypothesis is fundamental especialy if we want to be sure of the correctness of the results of _lm()_ and if we want to use the linear model to do *prediction* and not just to study the relationship between response variable and predictor.

```{r}
myresiduals <- mod$residuals
myresiduals
```

```{r}
modpred2 <- modpred %>% add_residuals(mod)
modpred2
```

```{r}
qqnorm(modpred2$resid)
qqline(modpred2$resid, lwd = 2, lty = 2, col = 'blue' ) # add a line joining the first and third quartiles of each distribution
```

```{r}
# Histogram of the residuals
hist( modpred2$resid , prob = TRUE, breaks = 20, col = "lightcoral", main = "Histogram of the residuals")

# Creating a Normality density line which is the line your data should have if gaussian.
griglia = sort( myresiduals ) # sort the data
lines( griglia, dnorm(griglia, mean = mean(myresiduals), sd = sd(myresiduals)), 
       col = 'maroon', lwd = 2 ) #I add the line simulating from a normal (dnorm)
 
```

```{r}
modpred2 %>%
  ggplot(aes(resid)) + 
  geom_histogram()
```

```{r}
shapiro.test(myresiduals)
```
if the p-value of the test if less than 0.05, then you reject the null hypothesis at 5% significance and conclude that your data is non-normal.

```{r}
mplot(mod)
```

* Residuals Vs Fitted (plot 1) and Scale-Location plot (plot 3): we are looking for particular pattern in the way the points are distributed. Are the points centered in 0? Are they scattered as a random clouds of points or without any particular shapes? If we answer yes to both the questions we can say that residuals have 0 mean and they are homoschedastic.

* Normal Q-Q (plot 2): the plot introduced before is reprosed here.

* 95% confidence interval: the 95% confidence interval obtained before are represented here with a 0 vertical line. If the confidence interval (horizontal line) cross the 0 vertical line it means that the corresponding $\beta$ is close to 0 (so not significant to explain the response variable)

















